{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariampinel/Neural-Networks-Deep-Learning/blob/main/NN_Coursework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "lpi8f-ocRNNt"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Pxa4nCSe2eUD",
        "outputId": "fca1e8dc-6cc5-4897-ffbd-6335868e1d8d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m771.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes\n",
        "- Fix dimensions\n",
        "- Task 2\n",
        "- Use: Convolutional neural networks are an example of architecture that exploits domain knowledge to improve performance.-> Find domain knowledge"
      ],
      "metadata": {
        "id": "CT2EPsxtVEEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Create a DataLoader for the training dataset and a DataLoader for the testing dataset, which should enable generating batches of examples"
      ],
      "metadata": {
        "id": "y1Cz7ZZ0RZhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformation to apply normalization and augmentation to training data\n",
        "def get_transforms(resize=None):\n",
        "    transform_list = [torchvision.transforms.ToTensor()]\n",
        "\n",
        "    if resize:\n",
        "        transform_list.insert(0, torchvision.transforms.Resize(resize))\n",
        "\n",
        "    transform_train = torchvision.transforms.Compose(transform_list)\n",
        "    transform_test = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "    return transform_train, transform_test\n",
        "\n",
        "# Load CIFAR-10 datasets using transformations\n",
        "def load_data_cifar10(batch_size, transform_train, transform_test):\n",
        "    cifar10_train = torchvision.datasets.CIFAR10(\n",
        "        root=\"../data\", train=True, transform=transform_train, download=True)\n",
        "    cifar10_test = torchvision.datasets.CIFAR10(\n",
        "        root=\"../data\", train=False, transform=transform_test, download=True)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        cifar10_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        cifar10_test, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    return train_loader, test_loader\n"
      ],
      "metadata": {
        "id": "gvChLr3JRon4"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train, validation and test split\n",
        "# Setting up hyperparameters and data loading\n",
        "batch_size = 256  # Modify batch size as required\n",
        "transform_train, transform_test = get_transforms(resize=None)\n",
        "train_loader, test_loader = load_data_cifar10(batch_size, transform_train, transform_test)\n"
      ],
      "metadata": {
        "id": "RKwPjpYkRzKF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Version checks\n",
        "# print(torch.__version__)\n",
        "# print(torchvision.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KfsPLjf2U3C",
        "outputId": "1515be1c-5b3f-428a-95fe-752613bf19d3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "0.21.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vars X and y\n",
        "# Create vars X and y\n",
        "X, y = next(iter(train_loader))  # Requests the first training batch from train_loader\n",
        "print(X.size()) # 256 images per batch. Each image is represented by a 1 x 32 x 32 tensor (number of channels x height x width). The images are color, so there are 3 channels.\n",
        "print(y.size()) # 256 targets. Each target is a number between 0 and 9. The classification problem has 10 clases."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYdtNQ-WR9gK",
        "outputId": "1dc210a3-a660-4ef4-e9dd-eaa692bd9a4e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 3, 32, 32])\n",
            "torch.Size([256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize data\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] # Pre-defined class labels\n",
        "\n",
        "for i in range(8):\n",
        "    print(f'\\nImage {i} ({class_labels[int(y[i])]}):\\n') # Prints the index `i` and the label associated to the `i`-th image.\n",
        "    cv2_imshow(X[i].numpy().transpose(1, 2, 0) * 255) # Converts and displays the `i`-th image in the batch."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "id": "idfDWK5OR_bo",
        "outputId": "87f66854-4abb-41da-9cd5-c0dcd3d73241"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Image 0 (bird):\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ],
            "image/png": "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\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDxklThlY5zkg1Z0yOee8C28Tyy4JCIMk1UKHZuzgCu2+GM89rrF5Ja7BdvZSiBmGcMMHj8qmcuWLZUIuTsjPvLiO7hhURvG1tAIzu4ySTn8aybhoJXWNF+VV2qQffrU8mqnUZ5ZJ1YXDktIxbO5vWtLwjFaSeJLNLp41SRygdhkKxHBI+uKV7IUlbY56aRWhVI1UL3BHetvw7rMmhi5khgDXCQPtZhyg7/AM/0p+n2UDafI06Rbww+cvjI64x2qtrM5triaWBRumjaGToy7Wx0Iodpe6whLlldGQjgSNLj73NLG7qyuhwRzn0q9p2j3OrQt9m8tSM7Vc4L4xnH5j86qvaTwECRdhBwVPB49aaFzJuyP//Z\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Image 1 (truck):\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ],
            "image/png": "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\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDodQ8VaVpJ23LSyORkJCufzJ4FMsfGmm3YZ5bKe3hEgjEit5hyemRgY/8Ar1lf8IHrWrMk0Qt0glXCGSTng5JxVuXwZcaLFYWss8bStOZsx5OTwAOe1DhTgtTVVatSXunQRaik6XEsUR8mIHYxP3yDg8dq4PUryOC5vJZiA3mgjjNb+mB7Lxu2nrJ5kE9o8o3DIB3Melbd94P0y+nWSS3UOr7soSuTwefWqiox1RjUc56N7HE6z4q1qw1O+trPVriO3tJNgWONdsZ6YzjNW7Px7jTd19cC6voEYwmeMhmY9uOMVpfFBLa4ga1tNLMV4sokeZVC+YMHPTrXnkekTWkcV3Md+1lLxbcnGaq6a1RF3F6M1LPxtPB4h/tSXToZJBCYdsZYDbnOe9dInxNu5pIyukQqrNk5lYnGR7VQt/BmoeJLuS+tIXgtZpN6K6BV9M1uad8MdXDxLd3FlDFGzZ8sM5YNjp6YxxUXQ1zH/9k=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Image 2 (truck):\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ],
            "image/png": "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\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwCDWtSdpIZ4ZmEBX95tP3hnpW9PqOnve2Xly+YzorqxX2JK/qK4mWRJpguIAn8W/g9a6Gy02GWSK6W4jgMYyP7o7V1QpVJapaGc60I6N6nR+G9ce0vFjtbxHtzNsmRzhFH972PWvUQEIUqwIboQc5r5/wBKkji1e+tz5cqo7Djo3OD/AOhGvQvCN3c+ZKLSRRBCgHkTMSFzk/L6dOlc2IwkZe9YqFS+nU8MVvNfzRJCgPJ804P4VrXWqzSaYllFOjXFx02sD3/Sse8tJ7yHYEAGcjAqDTtLvLPUI5xGGC5BwcECnCo4Xadrms6ana6vYmg1G70wSSPcotzExXYcEPnqf0Fd34W8TXWnJNJMkVzJI3BI27OCOMexNcr/AGVFPM0s8SszHJyK2LWOOFNoj+X24qJ1ZNWTNIUle7R//9k=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Image 3 (horse):\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAIZElEQVR4AYVWWY8cVxWuu9Te1d3V2/TY7bHHS1aIYxLkgJGi8IIQEggh8cTv4k+AJQQPCAkpyCAzKBnv2Ikdzz7TPdNL7dutu3DaxshJnHCn1XO76p71O+c7FymlNKVpSPv6UlJOZiemYXTana+//f9PnqnFoF0JqQmluHz2UZqQkktNao+3P7v+p98fHB2BLnj1/Ax8y1qwigkmNa5A9oXglzbLw6BWaRiEEVr6D9/P1nKLEZaS3b1/+9bmvfHR5OUzcK4os+3DXa4JDYPkC7kv//+fyNLAKxbW8jLb2TuYTeZ7Ozs1q0EPRLzMJ9L2Dvdu372d5dkz914h/fIj+vKP5/ulEqSB0jQrNCl0QiihoHf5h1GYhDc/+dfJbF5XFZyHBC+ff/N6hYEXUsuYG82mIOTx/q5j6GDJdpyNO7c+/WTz9KmRbhig/lu0L20r9EoDCCTrmvmd7rlLOFfy4dMvBr43PTmuNVKV1ZnRubffeqvhupqEtH3jep6JVxpYFgDjYnR2vVaGQsRrNi9duLS2Onr4+ItAootXLl+8cAET8i35gVcYozQLXmEAMsMlD7MsySuhkWbLH3Z9xzI7XrPf7U/m86P5NM7z48W83+7omHwVAdANUWGN1dmTp3eQgjC/EilGi3Cxcf/uvc+fUGK2PbeF6lbTG62vrw5PNdwGEzKMkzhNHKcxaLVsQp9n6r94LA2oWlS37t3c2LzxtQgQ9Bkbz44n8wDSXapysvN47/5t2zTe/9G1y1eunDl3ttXqtQAB2wqTZDqf9Vu+ZZmgVSoBuGK8LH1Wl7Dx7RZdmlPwGAEmsIcCDaJw92QSpnGepqysjra2kzA0fH9ycND2PJAuB8xttFzX6TRbGWSyzC3TKIssSOadzsDEjlKy4frfv3yt1WguCxzIIYoCx3YJJlyog+kkzrKyYrWS0ANeq9U01gcr/d5Kx/ZsSGmeJRUrGWu0233fbxdFXvN6fLx799GdH179sWVUntOM4tn23pO7nz+gcZEeTsafb/37/Ol1rFXEcncODiAYgBpi4kIMV4e+u6Yb1HUtwzCg60zTFBJ8CoWAU9ixLV6Lh9tbnz68a3n+cLAy7PYfPH7wcOszyzTpb3/3xzhID6f3oej7Dl4bDZOItXt923KURrhiWNf9FUh6g5elkpgSokNnIyqyrMjjIFAE90zDnafxzmTMbt/sDfppsKhL5nntKCnoPzY2kWJZ+ngWythvUl2vK9xod6hOl3hhDC4nedZut3urq1XJ0qoyqtK2bIijFrwqyyCcd7v06jvv3Xlw6+ne7kEcJFEkMkY4khXDYbK9SA/SJKvTijMrK3iYREVVKYQIBXeJYRpSquPZPAfK02lWFmEUxVkilIBIlBRxlIzH42F/+LOf/Fxv+osoycu64DyqCyYFTeYHyLC0isfFtItGAumalgFPIKIblpnzSi55FC0WiyAIOoCp52lCsJpBBCbwkW6AE2m0oJp499Ib33nz7b/87a9akFWCQy4JOFkWhY4xbdnMKLGbUnMomQV9CK4BsNSgJfQFq0TJeh3fJFRwUQvB87zIc7osBOU1XMe0TiZpLepr51/f/OfGsSiUrnMKkwO6wbax60jHEZSCS1CFhOpQyBJ2UKYYAx1DcuK8AHZyHdexLHhVcx5H0Ww2TZIYVhRFZVHub20NGo2PPrhm9jtcJ8A3rGCUrbQhZALjiRLkWhrRGg0bYqtrLqA3MSKYwuzjmjo8nkDHrZ89A1kBpRgma11DQQezmee5vu8DatHJ7HujtQ2dxkEmi4oDBu+fXodCU1wgSlrUrIs6lUyxajoPGeiHo4ylcSJY6VmGqYv98RHgAD5xVptUZ4yFMVBfXlVMJzScL4YrK9e+++7W7i6DvsUUffSLnz5jdKhJ4AsqGALZWrKy4NBFlmMCyBKRM2unoX8IXAVEBYPGBy6yjIYNrKAO9g+TMJvNFn63uXpqaOp6f21tc29vvAhgAtKnJIaLgW3bmmkM3cbr7TM21so83dk9DMJ0ESbQqMDVwfExEE7TbxYlz8L5DONT3XbleWAA8D6aHD99sn12fZRmKRQVJNbJeTEOhYYohuaCFLkm1kn31JmLq2+2EALkorLSLKcpkd9udTy7KKqj8SxncnR62Ov2pwc748k0izMwkKRJmidQAuOjKeeCcb66/nao8/kAcWJQ3AGFQupYIFUoBtejCmqyqoBkLMuwdMNxDMOEmvbUJEgzplH7ww8/0Kr0z3+4vr+9C2wDZFdmBbA3lNZ0HnT7/d7ojXl2qPjcMlxsmFQzYZ7rumZTpYMqgAI+bsOF2mi2G45jOo4DAIKzcJPKq7Lm8gdXr/3ql7/mXI0PYbIli0UMN7V2uyUBQGUEGUtEjYTO84qanQ50FQU4lKa7DWMJtUYQciwbYegMQ0fQ6VZSpJJi6Dte80dbO4Ned3TptdPnz258/HeiW0VVR3EahRlINladcTg/sYJS5VhptLO3lEQMS9A7SAsaKyCKooL2RXAZzPIkSYGT4JoFP2H+5Fk+OTzevP/oyluvvXv16sMHjxYnCygThEnFue21pIt29h+wFddrDXQmqD3XKJbAv3CobVHrrF7jQpfKsAzCq+WYVcCwyqTUtk24kUJ7aYTAiJnFyTvvXfU7g5s3buwf7p+UOXIcq99mXSdehLasjVqTMD5y85KmAAOGTUv2zh0V9iLMMMod+yTI24wTzdbqimP0FIgo5RXwElgBmqyAoyQarV/8zWtv5EVy/cbHu9FCWXpdppTYFnZdrJeSUb+3UgsqqoKYdtvvc5WnUJ9A0hByjaWGpZAEKSK5wkphDcgOniRw4wli37EXZW6aVqfhuNJAuaJ13StlKpRDgUjYPJr+B4PwPvp+Nf9gAAAAAElFTkSuQmCC\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD32uS0LWp/7W11b9pDGlz+5wpbbGBjt2qVvHOj3KzxWVyJZl4Xg4JOOf1rg9P1HWxrjS2l35cQcmZNuS/PegnmTdkeo6LqU2qQ3M8kLRRidkhDdWUY5rTz71j6feB3XIWN2GTt+63/ANesPUPHOkyadc288skFxuaIxhtjDBI69qV0O6W5454cnt7KWR5ZzJ905RGbofpWvB4htJL4fZZGLM5LLgoah0HbA9w3lsi7MZJ75qndwpDZzBVAbcDnPvWnJJaNHHTk7Xe528figQxeYjgwp97LciuX8YT2+ueXq2nSLJIQFmUMFB9G/pVzVNCufEXh+0uNHjgivY18uZd+3zhjg+m6uZ0izubC1mt7pYg0hB+U52hf/wBdZ8jubVKkfZ3Z/9k=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Image 4 (cat):\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ],
            "image/png": "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\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDynTrKSaVZTEWhHJJHGK9istfsotCicxk3CqFFtEAHJHfHYVyn9nyTQxP5fkTNGFlRRgA+v41Nc7bK5tpHUbnOwnHbHP8AKvQglpzbXObn1sdLb+Obe1C22uaZc2l02W2qm5WXPBFcVaaXba4+swRxkTFmntmIwduTwfwIro/GElvf6LYXoC+dauIHOeWUjhh+OK5vTrltM1ayuWfbliGJ/unqDSr03GpotzV6aHpVxpLakGmi2rOOB7j0rzzXVnbUILUfM6ShFIPfPNenaPK0kk+M5VcLz1OK5e20W41bxUlzgxpbtuaVkxhgf1NZp3ja5k1ZiGE38h0zU7cLIbQi2mxyxU9PYiuVu9HlurOGSPcz528f3gcfrXdarp7wX93cQw4kWQXJkLHk9D7AY7VrWPhtLq2d2YtFOyXARW2qrjqPccCu2bXsoTW6/Qtp2P/Z\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Image 5 (truck):\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ],
            "image/png": "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\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD1XwlfXF3pg8yRmKNjk5OO2ah8c+LrvwrZWctvZLMLmUwmVm4jbGRkd88/lXlun/FWfRGuLa2sYHRWIBmcgnH0qv4i8Y67400m2kTTvKtraVpTJFyMqOvJ7A1CXRCimkrnZeE/i1ea94jt9LudMjhEpKlgWBBAJzg/SvUFu0Y46V84+Htb1K/8c2uo3EyyXUYChym1eEYDOPTNdxD8QZL+B7d2ha4FyY1NvnOAMg/jg0mpLZjbPEnM0kT3ElmpiLYL4Oc/Wt3Q9c8jw5caZGjF5mIB3YGT0qm9+YtLksVRiMFduw889ar2O2KBSts6SJzySd59fatNhXb3NGBNQRH88qkoOeX5H4ineGIZbgTtC4V1YZO/aRwfY0kV4s6briKUHncg6n6fpUOnS3FpHeRW9m7pPwCwIKjJ7j8KEgbuj//Z\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Image 6 (airplane):\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ],
            "image/png": "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\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDvNH8RQ3t9Pp80H2e8hcjyy2dwHcGtPVJTb6dLcZ2+UVkOPQMCf0zXC+PLCazvLfXLNikgYK7L2YdD/Ss248XapeR3NtNcKsRj2SfKMHcOfpWPJ2NHO2jPUJJla48lBuwMsf7vp+dV5yOlcv4L8W6fq9u9oJSb1W3Nngye/PoB09q6K4mJyBhRVco1K4ahbW2o6fNaTAmORcZPY9iK8k17TINIstZkgeVo5JAkSv8AeQ4+bJ9hnn3Fehx3M0oxI5A6/LXP+M9Gu9R0F7XTog9xcSIpdmwEXdlifyFVFmc0eM6Nr09prSz27tFIzggr24x/WvSNHv8AxLqdysovHSFSCzS9CPp3qbw98NNM0TZcXsn2y8HOSMIp9h3/ABroLmJVztIXpjHoKbBJH//Z\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Image 7 (deer):\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ],
            "image/png": "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\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDtDfaVpR3ak4jTsCM5qG28UJHNEii6WBXARmjIXbjJOfTPFebfFKbyruC6sLqSSGT/AF6qx2Kw+6fb/wCtUuhfEQyRW5vZMBRtEZ5z75PNFGn7tobnRPXVnuN3drJFG6KZN4zwTiqLaUZUMlzLGjHkDAJ/OuU0z4i2E0bRSTJAkZI4bjH0xSy+LNMmv44xcMikH5mXC1E6c1LVChtocBqk4vkxGEPUFcY6VyU/h9DcoS7pb7vmC8kc4JH5iu0v41t5Ft0TYCCQR82PWtEaEb+1VFdJIQB0BRt2Oenau72fQ86nWk3dPc4pPCj6Zf2TNcG6t3Vp5AnBVVPf86dr1xKXYRbsKByOmD0rtoLeaymmiYJLLIAgBYDCgdMnHHNc14nsrqK0t0byC+1UdYpA7LjpkDmq5VFXZtCrNtJn/9k=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Implement the neural network architecture as described in this section to classify images from the CIFAR-10 dataset.\n",
        "\n",
        "The architecture is composed of a sequence of intermediate blocks B1, B2, . . . , BK that are followed by an output block O, as shown in Figure 2. These blocks are detailed in the following subsections.\n",
        "\n",
        "## Implement intermediate blocks"
      ],
      "metadata": {
        "id": "XCblPKJ4SBtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IntermediateBlock(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_layers):\n",
        "        super(IntermediateBlock, self).__init__()\n",
        "        self.num_layers = num_layers  # Store num_layers as an instance variable\n",
        "\n",
        "        # Independent convolutional layers\n",
        "        self.convs = torch.nn.ModuleList([\n",
        "            torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Fully connected layer to compute importance weights (a)\n",
        "        self.fc = torch.nn.Linear(in_channels, num_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, c, h, w = x.shape\n",
        "\n",
        "        # Apply each convolution independently\n",
        "        conv_outputs = torch.stack([conv(x) for conv in self.convs], dim=1)  # (batch, num_layers, out_channels, h, w)\n",
        "\n",
        "        # Compute per-channel average of x (to form m)\n",
        "        m = x.mean(dim=[2, 3])  # (batch, in_channels), average over height and width\n",
        "\n",
        "        # Compute weight vector a\n",
        "        a = self.fc(m)  # (batch, num_layers)\n",
        "        a = torch.softmax(a, dim=1)  # Normalize weights along num_layers\n",
        "\n",
        "        # Reshape a for broadcasting to the shape of conv_outputs\n",
        "        a = a.view(batch_size, self.num_layers, 1, 1)  # Use self.num_layers here\n",
        "\n",
        "        # Expand a to match the spatial dimensions of conv_outputs\n",
        "        a = a.expand(-1, -1, h, w)  # (batch, num_layers, h, w)\n",
        "\n",
        "        # Weighted sum of convolutional outputs\n",
        "        weighted_conv_outputs = (a.unsqueeze(2) * conv_outputs).sum(dim=1)  # (batch, out_channels, h, w)\n",
        "\n",
        "        return weighted_conv_outputs\n",
        "\n"
      ],
      "metadata": {
        "id": "IhWAuZuss_zS"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output block receives an image x (output of the last intermediate block) and outputs a logits vector o. Suppose that the input image x has c channels. In order to compute the vector o, the average value of each channel of x is computed and stored into a c-dimensional vector m. The vector m is the input to a sequence of zero or more fully connected layer(s) that output the vector o.\n",
        "c in this case is 3. Singe the images have 3 channels because they have colour."
      ],
      "metadata": {
        "id": "vVTcctaW4XrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output Block\n",
        "class OutputBlock(torch.nn.Module):\n",
        "    def __init__(self, num_outputs, in_channels, num_hidden_units=512, activation_function=torch.nn.ReLU):\n",
        "        super(OutputBlock, self).__init__()\n",
        "\n",
        "        # Define the fully connected layers for the output block\n",
        "        self.fc1 = torch.nn.Linear(in_channels, num_hidden_units)\n",
        "        self.fc2 = torch.nn.Linear(num_hidden_units, num_hidden_units // 4)  # Reduced size\n",
        "        self.fc3 = torch.nn.Linear(num_hidden_units // 4, num_outputs)\n",
        "\n",
        "        # Choose activation function\n",
        "        self.activation_function = activation_function\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Compute the per-channel average of x (global average pooling)\n",
        "        m = x.mean(dim=[2, 3])  # (batch, in_channels), average over height and width\n",
        "\n",
        "        # Pass the average through fully connected layers with activation functions\n",
        "        x = self.activation_function(self.fc1(m))\n",
        "        x = self.activation_function(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Whtc3u7b3uap"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10 Classifier with Intermediate and Output blocks\n",
        "class CIFAR10Classifier(torch.nn.Module):\n",
        "    def __init__(self, num_classes=10, num_hidden_units=512, num_layers=3, activation_function=torch.nn.ReLU):\n",
        "        super(CIFAR10Classifier, self).__init__()\n",
        "\n",
        "        # Define intermediate blocks\n",
        "        self.block1 = IntermediateBlock(in_channels=3, out_channels=num_hidden_units, num_layers=num_layers)\n",
        "        self.block2 = IntermediateBlock(in_channels=num_hidden_units, out_channels=num_hidden_units * 2, num_layers=num_layers)\n",
        "        self.block3 = IntermediateBlock(in_channels=num_hidden_units * 2, out_channels=num_hidden_units * 4, num_layers=num_layers)\n",
        "\n",
        "        # Define the output block\n",
        "        self.output_block = OutputBlock(num_outputs=num_classes, in_channels=num_hidden_units * 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through each intermediate block\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "\n",
        "        # Pass through the output block for final classification\n",
        "        x = self.output_block(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "BKtnmaiNODPr"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Weight inizialization"
      ],
      "metadata": {
        "id": "ibMwDt-KO-6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define weight initialization function\n",
        "def weight_init(m):\n",
        "    # Apply He initialization to Conv2d and Linear layers\n",
        "    if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
        "        torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            torch.nn.init.zeros_(m.bias)\n",
        ""
      ],
      "metadata": {
        "id": "oSJSLTn_PAvO"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DELETE\n",
        "# # Create the model with the current hyperparameters\n",
        "# model = CIFAR10Classifier(\n",
        "#     num_classes=10,\n",
        "#     num_hidden_units=hidden_units,\n",
        "#     num_layers=layers,\n",
        "#     activation_function=activation\n",
        "# )\n",
        "\n",
        "# # Apply weight initialization\n",
        "# model.apply(weight_init)  # Apply custom weight initialization\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "collapsed": true,
        "id": "XHOg5-wXQxtj",
        "outputId": "6dbe1642-4c0e-4532-a3a3-e4f897083b34"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "OutputBlock.__init__() got an unexpected keyword argument 'num_hidden_units'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-7fab75c68738>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create the model with the current hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = CIFAR10Classifier(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_hidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-d8de2271c052>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_classes, num_hidden_units, num_layers, activation_function)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Define the output block with tunable hidden units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOutputBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_hidden_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: OutputBlock.__init__() got an unexpected keyword argument 'num_hidden_units'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Loss function"
      ],
      "metadata": {
        "id": "_t6lz8nbOU6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Optimizer"
      ],
      "metadata": {
        "id": "-L0AK_s_OYH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train function\n",
        "def train(model, train_loader, optimizer, criterion, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, targets in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "# Evaluation function to check accuracy on the test dataset\n",
        "def evaluate(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_accuracy += (predicted == targets).sum().item()\n",
        "            total_samples += targets.size(0)\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "    avg_accuracy = total_accuracy / total_samples * 100\n",
        "    return avg_loss, avg_accuracy\n"
      ],
      "metadata": {
        "id": "UtSVDtJOOGSE"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter grid search\n",
        "learning_rates = [1e-3, 1e-4]\n",
        "batch_sizes = [128, 256]\n",
        "num_hidden_units = [512, 1024]\n",
        "activations = [torch.nn.ReLU, torch.nn.Sigmoid]\n",
        "num_layers = [3, 4]\n",
        "\n",
        "best_val_accuracy = 0\n",
        "best_model = None\n",
        "best_hyperparams = None\n",
        "\n",
        "# Loop over all combinations of hyperparameters\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        for hidden_units in num_hidden_units:\n",
        "            for activation in activations:\n",
        "                for layers in num_layers:\n",
        "                    print(f\"Training with lr={lr}, batch_size={batch_size}, hidden_units={hidden_units}, activation={activation}, num_layers={layers}\")\n",
        "\n",
        "                    # Create the model with the current hyperparameters\n",
        "                    model = CIFAR10Classifier(\n",
        "                        num_classes=10,\n",
        "                        num_hidden_units=hidden_units,\n",
        "                        num_layers=layers,\n",
        "                        activation_function=activation\n",
        "                    )\n",
        "\n",
        "                    # Apply weight initialization\n",
        "                    model.apply(weight_init)\n",
        "\n",
        "                    # Set up the optimizer (using Adam with the current learning rate)\n",
        "                    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "                    # Load data with the current batch size\n",
        "                    train_loader, test_loader = load_data_cifar10(batch_size=batch_size, transform_train=transform_train, transform_test=transform_test)\n",
        "\n",
        "                    # Define the loss function\n",
        "                    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "                    # Train the model\n",
        "                    train(model, train_loader, optimizer, criterion, num_epochs=10)\n",
        "\n",
        "                    # Evaluate on the testing dataset (acting as validation)\n",
        "                    val_loss, val_accuracy = evaluate(model, test_loader, criterion)\n",
        "\n",
        "                    # Save the best model based on validation accuracy\n",
        "                    if val_accuracy > best_val_accuracy:\n",
        "                        best_val_accuracy = val_accuracy\n",
        "                        best_model = model\n",
        "                        best_hyperparams = {\n",
        "                            'lr': lr,\n",
        "                            'batch_size': batch_size,\n",
        "                            'hidden_units': hidden_units,\n",
        "                            'activation': activation,\n",
        "                            'num_layers': layers\n",
        "                        }\n",
        "                        print(f\"New best model with accuracy {val_accuracy}%\")\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(f\"Best model achieved with hyperparameters: {best_hyperparams}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "17NfxokjV7PS",
        "outputId": "05c67bfa-3c35-4909-bdc9-7dabd67482eb"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with lr=0.001, batch_size=128, hidden_units=512, activation=<class 'torch.nn.modules.activation.ReLU'>, num_layers=3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-6cc867fff085>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0;31m# Evaluate on the testing dataset (acting as validation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-84-6dc2250f887f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-dd973586ea81>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Pass through the output block for final classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-4f9a208d9f8a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Apply each convolution independently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mconv_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch, num_layers, out_channels, h, w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Compute per-channel average of x (to form m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-4f9a208d9f8a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Apply each convolution independently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mconv_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch, num_layers, out_channels, h, w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Compute per-channel average of x (to form m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ". Train model"
      ],
      "metadata": {
        "id": "B8LL0_3kOh85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "train(model, train_loader, optimizer, criterion, num_epochs=10)"
      ],
      "metadata": {
        "id": "F1XcmcmOOknW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Evaluate model"
      ],
      "metadata": {
        "id": "sfDaYr6UOnCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}%\")"
      ],
      "metadata": {
        "id": "BFgvLzUmOova"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop over all combinations of hyperparameters\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        for hidden_units in num_hidden_units:\n",
        "            for activation in activations:\n",
        "                for layers in num_layers:\n",
        "                    print(f\"Training with lr={lr}, batch_size={batch_size}, hidden_units={hidden_units}, activation={activation}, num_layers={layers}\")\n",
        "\n",
        "                    # Create the model with the current hyperparameters\n",
        "                    model = CIFAR10Classifier(num_classes=10, num_hidden_units=hidden_units, num_layers=layers, activation_function=activation, batch_size=batch_size)\n",
        "\n",
        "                    # Apply weight initialization\n",
        "                    model.apply(weight_init)\n",
        "\n",
        "                    # Set up the optimizer\n",
        "                    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "                    # Load data with the current batch size\n",
        "                    train_loader, val_loader, test_loader = load_data_cifar10(batch_size=batch_size, transform_train=transform_train, transform_test=transform_test)\n",
        "\n",
        "                    # Define the loss function\n",
        "                    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "                    # Train the model\n",
        "                    train(model, train_loader, optimizer, criterion, num_epochs=10)\n",
        "\n",
        "                    # Evaluate on the validation set\n",
        "                    val_loss, val_accuracy = evaluate(model, val_loader, criterion)\n",
        "\n",
        "                    # Save the best model based on validation accuracy\n",
        "                    if val_accuracy > best_val_accuracy:\n",
        "                        best_val_accuracy = val_accuracy\n",
        "                        best_model = model\n",
        "                        best_hyperparams = {\n",
        "                            'lr': lr,\n",
        "                            'batch_size': batch_size,\n",
        "                            'hidden_units': hidden_units,\n",
        "                            'activation': activation,\n",
        "                            'num_layers': layers\n",
        "                        }\n",
        "                        print(f\"New best model with accuracy {val_accuracy}%\")\n",
        "\n",
        "print(f\"Best model achieved with hyperparameters: {best_hyperparams}\")\n"
      ],
      "metadata": {
        "id": "wKNrU_F-MTp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Losss function"
      ],
      "metadata": {
        "id": "0skbCGyqujyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "cMUhHJFAulhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Optimization algorithm"
      ],
      "metadata": {
        "id": "1vCk3HUvul-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.1\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "HKYVgTFRuvxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Evaluation"
      ],
      "metadata": {
        "id": "zAgjlbjbuw1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correct(logits, y):\n",
        "    y_hat = logits.argmax(axis=1) # Finds the column with the highest value for each row of `logits`.\n",
        "    return (y_hat == y).float().sum() # Computes the number of times that `y_hat` and `y` match.\n",
        "\n",
        "# Example: 1 correct classification,\n",
        "y = torch.tensor([2, 1])\n",
        "logits = torch.tensor([[0.1, 0.3, 0.6], [0.5, 0.2, 0.3]])\n",
        "print(correct(logits, y))"
      ],
      "metadata": {
        "id": "DXeQbagzuyLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_metric(net, data_iter, metric):\n",
        "    \"\"\"Compute the average `metric` of the model on a dataset.\"\"\"\n",
        "    c = torch.tensor(0.)\n",
        "    n = torch.tensor(0.)\n",
        "    for X, y in data_iter:\n",
        "        logits = net(X)\n",
        "        c += metric(logits, y)\n",
        "        n += len(y)\n",
        "\n",
        "    return c / n"
      ],
      "metadata": {
        "id": "V4gSNe9pu0sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training accuracy: {evaluate_metric(net, train_iter, correct)}. Testing accuracy: {evaluate_metric(net, test_iter, correct)}.')"
      ],
      "metadata": {
        "id": "hArJm8k6u2xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# References\n",
        "Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009."
      ],
      "metadata": {
        "id": "uKy_2mT1SD2X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}